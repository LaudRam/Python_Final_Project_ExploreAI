{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dda26281-672c-4f8c-bf4b-e9929f63426c",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "- <b> [1. Project Overview](#chapter1)\n",
    "    - [1.1. Introduction](#section_1_1)\n",
    "    - [1.2. Objective](#section_1_2)\n",
    "- <b> [2. Importing Packages](#chapter2)\n",
    "- <b> [3. Data Loading](#chapter3)\n",
    "- <b> [4. Data Cleaning](#chapter4)\n",
    "- <b> [5. Exploratory Data Analysis (EDA)](#chapter5)\n",
    "- <b> [6. Conclusion and Insights](#chapter6)</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6b1f49-c38e-4560-be3a-6e3abea5273d",
   "metadata": {},
   "source": [
    "# 1. Project Overview <a class=\"anchor\" id=\"chapter1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d900c7-1a07-4b64-a30d-a95f4cc54e2a",
   "metadata": {},
   "source": [
    "## 1.1. Introduction<a class=\"anchor\" id=\"section_1_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c83c437-783a-4d71-98e7-723438aacb42",
   "metadata": {},
   "source": [
    "Deforestation is one of the most significant modern challenges with extensive implications on the environment, economy and society. The process involves the reduction of forest area through the removal of vegetation and trees, leaving the land barren or significantly altered. This is typically driven by factors such as the expansion of agricultural fields, urban development and some industrial activities. The ongoing loss of forest area results in significant ramifications, including habitat destruction, biodiversity loss and the displacement of indigenous communities. Therefore, the understanding of deforestation trends is paramount for devising conservation strategies, identifying most affected countries and implementing sustainable practices.(references)\n",
    "\n",
    "This project aims to explore and analyse a World forest area dataset to identify deforestation trends and address key questions related to forest area. The data is sourced from Kaggle, uploaded by Takumi Watanabe and last updated 10 months ago.(reference) It comprises of the following features:\n",
    "* Country_name: list of country names, regions, and income statuses, with each element (country, region, income status) appearing as a distinct entry.\n",
    "* Country_code: A three letter code that distinctively represents a country.\n",
    "* 1990 - 2021 year columns: The annual total forest area  expressed in square kilometres.\n",
    " \n",
    "\n",
    "The key questions to be explored in this project are as follow:\n",
    "\n",
    "* What are the global trends in forest area from 1990 and 2021?\n",
    "* How does the rate of deforestation or afforestation compare across different countries?\n",
    "* Which countries, regions and income levels have seen the largest decrease or increase in forest area between 1990 and 2021?\n",
    "* What is the relationship between the rate of deforestation and Income status?\n",
    "* What is the relationship between rate of deforestation and region?\n",
    "\n",
    "\n",
    "This notebook is organised into several key sections to ensure a structured data analysis approach is employed. The approach leverages Python’s extensive data analysis and visualisation libraries to facilitate an in-depth examination of the dataset. This includes pandas, numpy, matplotlib and seaborn. In the Importing Packages section, these libraries are loaded.  The Data loading section details how the  data is loaded into a DataFrame and initial inspection is performed. In the Data Cleaning section, the data is cleaned and prepared for further analyses by handling missing or inconsistent data. The exploratory data analysis (EDA) section applies both data visualisations and statistical methods to uncover key trends and insights relevant to the project’s objective. The results of the analyses will provide a comprehensive understanding of global deforestation and afforestation trends, highlighting which countries have experienced the greatest losses or gains in forest area. This will be summarised and presented in the last section, Conclusion, including recommendations based on obtained insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa824009",
   "metadata": {},
   "source": [
    "### 1.1.1 Problem Statement<a class=\"anchor\" id=\"section_1_1_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e117c4",
   "metadata": {},
   "source": [
    "How has forest area changed globally over the years and which countries, regions and income levels are most affected ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2696fdf2-ef64-4375-a3a8-cfa7477da75f",
   "metadata": {},
   "source": [
    "## 1.2. Objective<a class=\"anchor\" id=\"section_1_2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b78893-f95f-4bc4-b2f6-a5dd366a9154",
   "metadata": {},
   "source": [
    "* To perform exploratory data analysis of the global deforestation dataset.\n",
    "* To analyse the change in global forest area from 1990 and 2021, identifying trends of deforestation or afforestation for each country.\n",
    "* To identify countries, regions and income levels that have the largest decrease and increase in forest area between 1990 and 2021.\n",
    "* To determine the relationship between income status and rate of deforestation.\n",
    "* To determine the relationship between various regions and rate of deforestation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daebff2e-2776-4e5f-a8b9-45d8a9450578",
   "metadata": {},
   "source": [
    "# 2. Importing Packages<a class=\"anchor\" id=\"chapter2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c20abe3-a3f8-47df-a0cd-c30f124fa015",
   "metadata": {},
   "source": [
    "Importing notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f58ed033-ec54-4e2f-aab2-7e0eb29a93fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for data loading, manipulation and analysis\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Displays output inline\n",
    "%matplotlib inline\n",
    "\n",
    "# Libraries for Handing Errors\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c5bcee-5cc1-40a0-b371-4e25b112d12d",
   "metadata": {},
   "source": [
    "# 3. Data Loading<a class=\"anchor\" id=\"chapter3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd3bf5f-8c58-43ff-9c9d-04d0fd518022",
   "metadata": {},
   "source": [
    "Loading notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69c4ff4f-9892-4706-8573-3e4bd5f500d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all columns\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c6b3640-d353-4d7b-b183-02a0d8552005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country Name</th>\n",
       "      <th>Country Code</th>\n",
       "      <th>1990</th>\n",
       "      <th>1991</th>\n",
       "      <th>1992</th>\n",
       "      <th>1993</th>\n",
       "      <th>1994</th>\n",
       "      <th>1995</th>\n",
       "      <th>1996</th>\n",
       "      <th>1997</th>\n",
       "      <th>1998</th>\n",
       "      <th>1999</th>\n",
       "      <th>2000</th>\n",
       "      <th>2001</th>\n",
       "      <th>2002</th>\n",
       "      <th>2003</th>\n",
       "      <th>2004</th>\n",
       "      <th>2005</th>\n",
       "      <th>2006</th>\n",
       "      <th>2007</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>2021</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>12084.4</td>\n",
       "      <td>12084.40</td>\n",
       "      <td>12084.40</td>\n",
       "      <td>12084.40</td>\n",
       "      <td>12084.40</td>\n",
       "      <td>12084.4</td>\n",
       "      <td>12084.40</td>\n",
       "      <td>12084.40</td>\n",
       "      <td>12084.40</td>\n",
       "      <td>12084.40</td>\n",
       "      <td>12084.4</td>\n",
       "      <td>12084.40</td>\n",
       "      <td>12084.40</td>\n",
       "      <td>12084.40</td>\n",
       "      <td>12084.40</td>\n",
       "      <td>12084.40</td>\n",
       "      <td>12084.40</td>\n",
       "      <td>12084.40</td>\n",
       "      <td>12084.40</td>\n",
       "      <td>12084.40</td>\n",
       "      <td>12084.4</td>\n",
       "      <td>12084.400</td>\n",
       "      <td>12084.40</td>\n",
       "      <td>12084.400</td>\n",
       "      <td>12084.40</td>\n",
       "      <td>12084.400</td>\n",
       "      <td>12084.4</td>\n",
       "      <td>12084.400</td>\n",
       "      <td>12084.4</td>\n",
       "      <td>12084.4</td>\n",
       "      <td>12084.4</td>\n",
       "      <td>12084.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>ALB</td>\n",
       "      <td>7888.0</td>\n",
       "      <td>7868.50</td>\n",
       "      <td>7849.00</td>\n",
       "      <td>7829.50</td>\n",
       "      <td>7810.00</td>\n",
       "      <td>7790.5</td>\n",
       "      <td>7771.00</td>\n",
       "      <td>7751.50</td>\n",
       "      <td>7732.00</td>\n",
       "      <td>7712.50</td>\n",
       "      <td>7693.0</td>\n",
       "      <td>7705.77</td>\n",
       "      <td>7718.54</td>\n",
       "      <td>7731.31</td>\n",
       "      <td>7744.08</td>\n",
       "      <td>7756.85</td>\n",
       "      <td>7769.62</td>\n",
       "      <td>7782.39</td>\n",
       "      <td>7795.16</td>\n",
       "      <td>7807.93</td>\n",
       "      <td>7820.7</td>\n",
       "      <td>7834.935</td>\n",
       "      <td>7849.17</td>\n",
       "      <td>7863.405</td>\n",
       "      <td>7877.64</td>\n",
       "      <td>7891.875</td>\n",
       "      <td>7891.8</td>\n",
       "      <td>7889.025</td>\n",
       "      <td>7889.0</td>\n",
       "      <td>7889.0</td>\n",
       "      <td>7889.0</td>\n",
       "      <td>7889.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>DZA</td>\n",
       "      <td>16670.0</td>\n",
       "      <td>16582.00</td>\n",
       "      <td>16494.00</td>\n",
       "      <td>16406.00</td>\n",
       "      <td>16318.00</td>\n",
       "      <td>16230.0</td>\n",
       "      <td>16142.00</td>\n",
       "      <td>16054.00</td>\n",
       "      <td>15966.00</td>\n",
       "      <td>15878.00</td>\n",
       "      <td>15790.0</td>\n",
       "      <td>16129.00</td>\n",
       "      <td>16468.00</td>\n",
       "      <td>16807.00</td>\n",
       "      <td>17146.00</td>\n",
       "      <td>17485.00</td>\n",
       "      <td>17824.00</td>\n",
       "      <td>18163.00</td>\n",
       "      <td>18502.00</td>\n",
       "      <td>18841.00</td>\n",
       "      <td>19180.0</td>\n",
       "      <td>19256.000</td>\n",
       "      <td>19332.00</td>\n",
       "      <td>19408.000</td>\n",
       "      <td>19484.00</td>\n",
       "      <td>19560.000</td>\n",
       "      <td>19560.0</td>\n",
       "      <td>19430.000</td>\n",
       "      <td>19300.0</td>\n",
       "      <td>19390.0</td>\n",
       "      <td>19490.0</td>\n",
       "      <td>19583.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>American Samoa</td>\n",
       "      <td>ASM</td>\n",
       "      <td>180.7</td>\n",
       "      <td>180.36</td>\n",
       "      <td>180.02</td>\n",
       "      <td>179.68</td>\n",
       "      <td>179.34</td>\n",
       "      <td>179.0</td>\n",
       "      <td>178.66</td>\n",
       "      <td>178.32</td>\n",
       "      <td>177.98</td>\n",
       "      <td>177.64</td>\n",
       "      <td>177.3</td>\n",
       "      <td>177.00</td>\n",
       "      <td>176.70</td>\n",
       "      <td>176.40</td>\n",
       "      <td>176.10</td>\n",
       "      <td>175.80</td>\n",
       "      <td>175.50</td>\n",
       "      <td>175.20</td>\n",
       "      <td>174.90</td>\n",
       "      <td>174.60</td>\n",
       "      <td>174.3</td>\n",
       "      <td>174.000</td>\n",
       "      <td>173.70</td>\n",
       "      <td>173.400</td>\n",
       "      <td>173.10</td>\n",
       "      <td>172.800</td>\n",
       "      <td>172.5</td>\n",
       "      <td>172.200</td>\n",
       "      <td>171.9</td>\n",
       "      <td>171.6</td>\n",
       "      <td>171.3</td>\n",
       "      <td>171.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>AND</td>\n",
       "      <td>160.0</td>\n",
       "      <td>160.00</td>\n",
       "      <td>160.00</td>\n",
       "      <td>160.00</td>\n",
       "      <td>160.00</td>\n",
       "      <td>160.0</td>\n",
       "      <td>160.00</td>\n",
       "      <td>160.00</td>\n",
       "      <td>160.00</td>\n",
       "      <td>160.00</td>\n",
       "      <td>160.0</td>\n",
       "      <td>160.00</td>\n",
       "      <td>160.00</td>\n",
       "      <td>160.00</td>\n",
       "      <td>160.00</td>\n",
       "      <td>160.00</td>\n",
       "      <td>160.00</td>\n",
       "      <td>160.00</td>\n",
       "      <td>160.00</td>\n",
       "      <td>160.00</td>\n",
       "      <td>160.0</td>\n",
       "      <td>160.000</td>\n",
       "      <td>160.00</td>\n",
       "      <td>160.000</td>\n",
       "      <td>160.00</td>\n",
       "      <td>160.000</td>\n",
       "      <td>160.0</td>\n",
       "      <td>160.000</td>\n",
       "      <td>160.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>160.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Country Name Country Code     1990      1991      1992      1993  \\\n",
       "0     Afghanistan          AFG  12084.4  12084.40  12084.40  12084.40   \n",
       "1         Albania          ALB   7888.0   7868.50   7849.00   7829.50   \n",
       "2         Algeria          DZA  16670.0  16582.00  16494.00  16406.00   \n",
       "3  American Samoa          ASM    180.7    180.36    180.02    179.68   \n",
       "4         Andorra          AND    160.0    160.00    160.00    160.00   \n",
       "\n",
       "       1994     1995      1996      1997      1998      1999     2000  \\\n",
       "0  12084.40  12084.4  12084.40  12084.40  12084.40  12084.40  12084.4   \n",
       "1   7810.00   7790.5   7771.00   7751.50   7732.00   7712.50   7693.0   \n",
       "2  16318.00  16230.0  16142.00  16054.00  15966.00  15878.00  15790.0   \n",
       "3    179.34    179.0    178.66    178.32    177.98    177.64    177.3   \n",
       "4    160.00    160.0    160.00    160.00    160.00    160.00    160.0   \n",
       "\n",
       "       2001      2002      2003      2004      2005      2006      2007  \\\n",
       "0  12084.40  12084.40  12084.40  12084.40  12084.40  12084.40  12084.40   \n",
       "1   7705.77   7718.54   7731.31   7744.08   7756.85   7769.62   7782.39   \n",
       "2  16129.00  16468.00  16807.00  17146.00  17485.00  17824.00  18163.00   \n",
       "3    177.00    176.70    176.40    176.10    175.80    175.50    175.20   \n",
       "4    160.00    160.00    160.00    160.00    160.00    160.00    160.00   \n",
       "\n",
       "       2008      2009     2010       2011      2012       2013      2014  \\\n",
       "0  12084.40  12084.40  12084.4  12084.400  12084.40  12084.400  12084.40   \n",
       "1   7795.16   7807.93   7820.7   7834.935   7849.17   7863.405   7877.64   \n",
       "2  18502.00  18841.00  19180.0  19256.000  19332.00  19408.000  19484.00   \n",
       "3    174.90    174.60    174.3    174.000    173.70    173.400    173.10   \n",
       "4    160.00    160.00    160.0    160.000    160.00    160.000    160.00   \n",
       "\n",
       "        2015     2016       2017     2018     2019     2020       2021  \n",
       "0  12084.400  12084.4  12084.400  12084.4  12084.4  12084.4  12084.400  \n",
       "1   7891.875   7891.8   7889.025   7889.0   7889.0   7889.0   7889.000  \n",
       "2  19560.000  19560.0  19430.000  19300.0  19390.0  19490.0  19583.333  \n",
       "3    172.800    172.5    172.200    171.9    171.6    171.3    171.000  \n",
       "4    160.000    160.0    160.000    160.0    160.0    160.0    160.000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading dataset\n",
    "original_df = pd.read_csv(\"forest_area_km.csv\", index_col=False)\n",
    "\n",
    "# Display the first few rows\n",
    "original_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3adf0da0-6d14-4825-8ddb-f1f7ec6249a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create copy of dataset\n",
    "df = original_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3ab9378-9852-4894-8b95-e1fb88082d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace spaces with underscores\n",
    "df.columns = [col.replace(' ', '_') for col in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28e1b028-cb36-4b4c-9543-577a8c648cbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(259, 34)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displays number of rows and columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef98607-02b8-43a2-89b7-c1723af0be39",
   "metadata": {},
   "source": [
    "**Results**: The dataset consists of 259 rows and 34 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6497ed9-b2a4-4c16-9ffe-823a162e95db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 259 entries, 0 to 258\n",
      "Data columns (total 34 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Country_Name  259 non-null    object \n",
      " 1   Country_Code  259 non-null    object \n",
      " 2   1990          215 non-null    float64\n",
      " 3   1991          219 non-null    float64\n",
      " 4   1992          248 non-null    float64\n",
      " 5   1993          251 non-null    float64\n",
      " 6   1994          251 non-null    float64\n",
      " 7   1995          251 non-null    float64\n",
      " 8   1996          251 non-null    float64\n",
      " 9   1997          251 non-null    float64\n",
      " 10  1998          251 non-null    float64\n",
      " 11  1999          251 non-null    float64\n",
      " 12  2000          253 non-null    float64\n",
      " 13  2001          253 non-null    float64\n",
      " 14  2002          253 non-null    float64\n",
      " 15  2003          253 non-null    float64\n",
      " 16  2004          253 non-null    float64\n",
      " 17  2005          253 non-null    float64\n",
      " 18  2006          255 non-null    float64\n",
      " 19  2007          255 non-null    float64\n",
      " 20  2008          255 non-null    float64\n",
      " 21  2009          255 non-null    float64\n",
      " 22  2010          255 non-null    float64\n",
      " 23  2011          258 non-null    float64\n",
      " 24  2012          259 non-null    float64\n",
      " 25  2013          259 non-null    float64\n",
      " 26  2014          259 non-null    float64\n",
      " 27  2015          259 non-null    float64\n",
      " 28  2016          259 non-null    float64\n",
      " 29  2017          259 non-null    float64\n",
      " 30  2018          259 non-null    float64\n",
      " 31  2019          259 non-null    float64\n",
      " 32  2020          259 non-null    float64\n",
      " 33  2021          259 non-null    float64\n",
      "dtypes: float64(32), object(2)\n",
      "memory usage: 68.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1deda130-41ab-428a-9e9c-399bb34a885e",
   "metadata": {},
   "source": [
    "**Results**: Country_Name and Country_Code are objects with no null values, columns 1990 - 2011 have some null values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582cdf56-ee9c-4aa2-9916-870bd9cb9d59",
   "metadata": {},
   "source": [
    "# 4. Data Cleaning<a class=\"anchor\" id=\"chapter4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec595c58-4075-4c32-b512-08c01fc88498",
   "metadata": {},
   "source": [
    "Before cleaning, inspect the data for any issues (null values, duplicates, non-essential columns or rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736bbb91-a031-4ab4-92f3-8050056479b2",
   "metadata": {},
   "source": [
    "`print_null_values` function notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fe8eb98-e04b-4f42-b62b-bc720f388f30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with null values:\n",
      "1990    44\n",
      "1991    40\n",
      "1992    11\n",
      "1993     8\n",
      "1994     8\n",
      "1995     8\n",
      "1996     8\n",
      "1997     8\n",
      "1998     8\n",
      "1999     8\n",
      "2000     6\n",
      "2001     6\n",
      "2002     6\n",
      "2003     6\n",
      "2004     6\n",
      "2005     6\n",
      "2006     4\n",
      "2007     4\n",
      "2008     4\n",
      "2009     4\n",
      "2010     4\n",
      "2011     1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def print_null_values(df):\n",
    "    \"\"\"\n",
    "    Prints the count of null (missing) values for each column that has more than 0 null values.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The input DataFrame to check for null values.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    null_counts = df.isnull().sum()\n",
    "    \n",
    "    # Filter out columns with no null values\n",
    "    null_counts = null_counts[null_counts > 0]\n",
    "    \n",
    "    if null_counts.empty:\n",
    "        print(\"No columns with null values.\")\n",
    "    else:\n",
    "        print(\"Columns with null values:\")\n",
    "        print(null_counts)\n",
    "        \n",
    "\n",
    "print_null_values(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b209c905-08de-4d55-9cb1-6a77e71f428f",
   "metadata": {},
   "source": [
    "**Results**: The columns from 1990 to 2011 contain missing values, with the earliest years (1990-1992) having the most missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e8cc6e-a416-48a4-9518-69176e348e0f",
   "metadata": {},
   "source": [
    "`trim_spaces` function to remove leading and trailing spaces before checking for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f21f21b-281d-4f34-9d6f-7c9d2ee21f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_spaces(df, columns):\n",
    "    \"\"\"\n",
    "    Trims leading and trailing spaces from the specified columns in a DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The input DataFrame to trim.\n",
    "    columns (list): List of object columns to trim spaces from.\n",
    "    \"\"\"\n",
    "    for column in columns:\n",
    "        df[column] = df[column].str.strip()\n",
    "    \n",
    "    return df\n",
    "\n",
    "trim_columns = ['Country_Name', 'Country_Code']\n",
    "df = trim_spaces(df, trim_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e34fd4-ad50-4785-a1b6-72e4c28c640c",
   "metadata": {},
   "source": [
    "`count_duplicate_rows` function notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f26872c0-9069-4c56-8bdb-5071cec2f792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "def count_duplicate_rows(df):\n",
    "    \"\"\"\n",
    "    Counts the number of duplicate rows in a DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The input DataFrame to check duplicates.\n",
    "    \n",
    "    Returns:\n",
    "    int: The count of duplicate rows.\n",
    "    \"\"\"\n",
    "    return df.duplicated().sum()\n",
    "\n",
    "print(\"Number of duplicate rows:\", count_duplicate_rows(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c28153-3b67-45f9-9802-29c4c2d70282",
   "metadata": {},
   "source": [
    "Non-essential rows notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adfd7411-4d49-4d9e-9fab-89db42a535fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country_Name</th>\n",
       "      <th>Country_Code</th>\n",
       "      <th>1990</th>\n",
       "      <th>1991</th>\n",
       "      <th>1992</th>\n",
       "      <th>1993</th>\n",
       "      <th>1994</th>\n",
       "      <th>1995</th>\n",
       "      <th>1996</th>\n",
       "      <th>1997</th>\n",
       "      <th>1998</th>\n",
       "      <th>1999</th>\n",
       "      <th>2000</th>\n",
       "      <th>2001</th>\n",
       "      <th>2002</th>\n",
       "      <th>2003</th>\n",
       "      <th>2004</th>\n",
       "      <th>2005</th>\n",
       "      <th>2006</th>\n",
       "      <th>2007</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>2021</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Gibraltar</td>\n",
       "      <td>GIB</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country_Name Country_Code  1990  1991  1992  1993  1994  1995  1996  1997  \\\n",
       "75    Gibraltar          GIB   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "    1998  1999  2000  2001  2002  2003  2004  2005  2006  2007  2008  2009  \\\n",
       "75   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "    2010  2011  2012  2013  2014  2015  2016  2017  2018  2019  2020  2021  \n",
       "75   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for rows with all zeroes\n",
    "zero_rows = df.loc[df.iloc[:, 2:].eq(0).all(axis=1)]\n",
    "zero_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c55238db-d314-4f23-94fc-1ee3e0f749dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(258, 34)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove rows that contain only zeroes\n",
    "df = df.drop(zero_rows.index)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34c7c60-70fe-40df-a486-d3005dabdf53",
   "metadata": {},
   "source": [
    "**Results**: 1 row removed, dataset now consists of 258 rows and 34 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2650c9a-073f-4350-b683-c2e812858e2f",
   "metadata": {},
   "source": [
    "`check_column_data_types` function notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56a1086a-30c2-4a4f-a0e9-ddf2f762efa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All columns have the correct data types.\n"
     ]
    }
   ],
   "source": [
    "def check_column_data_types(df, object_columns):\n",
    "    \"\"\"\n",
    "    Checks if specified columns are of type object and the rest are of type float.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The input DataFrame to check data types.\n",
    "    object_columns (list): List of columns expected to be of type object.\n",
    "    \"\"\"\n",
    "    mismatches = []\n",
    "    \n",
    "    for column in df.columns:\n",
    "        expected_type = 'object' if column in object_columns else 'float64'\n",
    "        actual_type = df[column].dtype\n",
    "        \n",
    "        if actual_type != expected_type:\n",
    "            mismatches.append((column, actual_type, expected_type))\n",
    "    \n",
    "    if mismatches:\n",
    "        for column, actual, expected in mismatches:\n",
    "            print(f\"Column '{column}' has data type '{actual}', expected '{expected}'.\")\n",
    "    else:\n",
    "        print(\"All columns have the correct data types.\")\n",
    "\n",
    "object_columns = ['Country_Name', 'Country_Code']\n",
    "check_column_data_types(df, object_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a675cb-4417-4ff5-9dcb-ea3caff84170",
   "metadata": {},
   "source": [
    "Handling null values notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8324331c-dc19-4916-9fb1-7de6d43d136f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(254, 34)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def drop_rows_with_too_many_nulls(df, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Drops rows with more than a specified percentage of null values.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The input DataFrame.\n",
    "    threshold (float): The maximum percentage of null values allowed in a row (default 0.5 = 50%).\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: The DataFrame with rows dropped based on the threshold.\n",
    "    \"\"\"\n",
    "    # Calculate the percentage of null values per row\n",
    "    null_percentage = df.isnull().mean(axis=1)\n",
    "    \n",
    "    # Drop rows where the percentage of null values is greater than the threshold\n",
    "    return df[null_percentage <= threshold]\n",
    "\n",
    "df_nulls_preprocessed = drop_rows_with_too_many_nulls(df)\n",
    "df_nulls_preprocessed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3558a4a1-5fba-484f-ac44-cfd5e7ebe7a2",
   "metadata": {},
   "source": [
    "**Result**: Dropped 4 rows with over 50% null values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13171746-36ef-4818-85a1-399d95c19f98",
   "metadata": {},
   "source": [
    "To avoid inaccuracies when filling missing values, drop rows with more than 9 null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53b272d0-03ce-4e16-8239-eb42b1a6f604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 34)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def drop_rows_with_excessive_nulls(df, max_nulls=9):\n",
    "    \"\"\"\n",
    "    Drops rows with more than a specified number of null values.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The input DataFrame.\n",
    "    max_nulls (int): The maximum number of null values allowed in a row.\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: The DataFrame with rows dropped based on the maximum null count.\n",
    "    \"\"\"\n",
    "    # Keep only rows where the number of nulls is less than or equal to max_nulls\n",
    "    return df[df.isnull().sum(axis=1) < max_nulls]\n",
    "\n",
    "df_nulls_processed = drop_rows_with_excessive_nulls(df_nulls_preprocessed)\n",
    "df_nulls_processed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2383d00f-28f1-49b7-93d5-9d3efbf731eb",
   "metadata": {},
   "source": [
    "**Result**: Dropped 4 rows with over 9 null values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c523a205-9901-4d80-b83a-ce92bbe433e3",
   "metadata": {},
   "source": [
    "Fill missing values using `bfill_nulls` (Fill Backward) function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dab3c8b8-5b66-4e99-a68f-20654b3137bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bfill_nulls(df):\n",
    "    # Apply bfill to all columns except the Country columns\n",
    "    df.iloc[:, 2:] = df.iloc[:, 2:].bfill(axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_nulls_filled = bfill_nulls(df_nulls_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a500f16e-9c80-4edd-bf5e-df474d7864e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No columns with null values.\n"
     ]
    }
   ],
   "source": [
    "# Confirm that bfill_nulls filled all nulls\n",
    "print_null_values(df_nulls_filled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d963a25-8a95-4c79-910a-501f8756d8c5",
   "metadata": {},
   "source": [
    "`standardise_float_columns` function used to standardise numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "588065b7-0315-404e-981a-5b00a2da3a52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country_Name</th>\n",
       "      <th>Country_Code</th>\n",
       "      <th>1990</th>\n",
       "      <th>1991</th>\n",
       "      <th>1992</th>\n",
       "      <th>1993</th>\n",
       "      <th>1994</th>\n",
       "      <th>1995</th>\n",
       "      <th>1996</th>\n",
       "      <th>1997</th>\n",
       "      <th>1998</th>\n",
       "      <th>1999</th>\n",
       "      <th>2000</th>\n",
       "      <th>2001</th>\n",
       "      <th>2002</th>\n",
       "      <th>2003</th>\n",
       "      <th>2004</th>\n",
       "      <th>2005</th>\n",
       "      <th>2006</th>\n",
       "      <th>2007</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>2021</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>12084.4</td>\n",
       "      <td>12084.4</td>\n",
       "      <td>12084.4</td>\n",
       "      <td>12084.4</td>\n",
       "      <td>12084.4</td>\n",
       "      <td>12084.4</td>\n",
       "      <td>12084.4</td>\n",
       "      <td>12084.4</td>\n",
       "      <td>12084.4</td>\n",
       "      <td>12084.4</td>\n",
       "      <td>12084.4</td>\n",
       "      <td>12084.40</td>\n",
       "      <td>12084.40</td>\n",
       "      <td>12084.40</td>\n",
       "      <td>12084.40</td>\n",
       "      <td>12084.40</td>\n",
       "      <td>12084.40</td>\n",
       "      <td>12084.40</td>\n",
       "      <td>12084.40</td>\n",
       "      <td>12084.40</td>\n",
       "      <td>12084.4</td>\n",
       "      <td>12084.40</td>\n",
       "      <td>12084.40</td>\n",
       "      <td>12084.4</td>\n",
       "      <td>12084.40</td>\n",
       "      <td>12084.40</td>\n",
       "      <td>12084.4</td>\n",
       "      <td>12084.40</td>\n",
       "      <td>12084.4</td>\n",
       "      <td>12084.4</td>\n",
       "      <td>12084.4</td>\n",
       "      <td>12084.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>ALB</td>\n",
       "      <td>7888.0</td>\n",
       "      <td>7868.5</td>\n",
       "      <td>7849.0</td>\n",
       "      <td>7829.5</td>\n",
       "      <td>7810.0</td>\n",
       "      <td>7790.5</td>\n",
       "      <td>7771.0</td>\n",
       "      <td>7751.5</td>\n",
       "      <td>7732.0</td>\n",
       "      <td>7712.5</td>\n",
       "      <td>7693.0</td>\n",
       "      <td>7705.77</td>\n",
       "      <td>7718.54</td>\n",
       "      <td>7731.31</td>\n",
       "      <td>7744.08</td>\n",
       "      <td>7756.85</td>\n",
       "      <td>7769.62</td>\n",
       "      <td>7782.39</td>\n",
       "      <td>7795.16</td>\n",
       "      <td>7807.93</td>\n",
       "      <td>7820.7</td>\n",
       "      <td>7834.94</td>\n",
       "      <td>7849.17</td>\n",
       "      <td>7863.4</td>\n",
       "      <td>7877.64</td>\n",
       "      <td>7891.88</td>\n",
       "      <td>7891.8</td>\n",
       "      <td>7889.02</td>\n",
       "      <td>7889.0</td>\n",
       "      <td>7889.0</td>\n",
       "      <td>7889.0</td>\n",
       "      <td>7889.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Country_Name Country_Code     1990     1991     1992     1993     1994  \\\n",
       "0  Afghanistan          AFG  12084.4  12084.4  12084.4  12084.4  12084.4   \n",
       "1      Albania          ALB   7888.0   7868.5   7849.0   7829.5   7810.0   \n",
       "\n",
       "      1995     1996     1997     1998     1999     2000      2001      2002  \\\n",
       "0  12084.4  12084.4  12084.4  12084.4  12084.4  12084.4  12084.40  12084.40   \n",
       "1   7790.5   7771.0   7751.5   7732.0   7712.5   7693.0   7705.77   7718.54   \n",
       "\n",
       "       2003      2004      2005      2006      2007      2008      2009  \\\n",
       "0  12084.40  12084.40  12084.40  12084.40  12084.40  12084.40  12084.40   \n",
       "1   7731.31   7744.08   7756.85   7769.62   7782.39   7795.16   7807.93   \n",
       "\n",
       "      2010      2011      2012     2013      2014      2015     2016  \\\n",
       "0  12084.4  12084.40  12084.40  12084.4  12084.40  12084.40  12084.4   \n",
       "1   7820.7   7834.94   7849.17   7863.4   7877.64   7891.88   7891.8   \n",
       "\n",
       "       2017     2018     2019     2020     2021  \n",
       "0  12084.40  12084.4  12084.4  12084.4  12084.4  \n",
       "1   7889.02   7889.0   7889.0   7889.0   7889.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def standardise_float_columns(df, start_col):\n",
    "    \"\"\"\n",
    "    Converts specified columns with scientific notation to regular float format.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The DataFrame containing columns to format.\n",
    "    start_col (int): The index of the first column to format.\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: DataFrame with specified columns formatted as floats.\n",
    "    \"\"\"\n",
    "    # Format each column in the sliced list to float and round\n",
    "    columns_to_format = df.columns[start_col:]\n",
    "    for col in columns_to_format:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')  # Convert to numeric\n",
    "        df[col] = df[col].round(2)  # Round to 2 decimals\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Format columns starting from the third column onward\n",
    "df_clean = standardise_float_columns(df_nulls_filled, start_col=2)\n",
    "df_clean.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9054035-da51-4c4b-8626-3107d9aae33a",
   "metadata": {},
   "source": [
    "# 5. Exploratory Data Analysis (EDA)<a class=\"anchor\" id=\"chapter5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99962f5c-9a40-435e-b992-67b115609439",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9df3d05-52a0-4a29-83e5-4ed4607ab9e5",
   "metadata": {},
   "source": [
    "# 6. Conclusion and Insights <a class=\"anchor\" id=\"chapter6\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d901d9e1-6b14-4ae0-b9d8-e6cbfeab2b28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
